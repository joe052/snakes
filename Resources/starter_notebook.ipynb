{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Snakes and Sequences: Senegalese Serpent Venom Sequencing Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://ideogram.ai/assets/image/lossless/response/OSUbpH_nTg6_IHiRw-9YPg' />\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "<font color='grey'>Image source: created using [ideogram.ai](https://ideogram.ai/g/CD9hdRnmQTCEIMGBfiDeiw/2)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "\n",
    "Snakes pose a significant danger in Senegal, where encounters with venomous species can lead to severe injury or even death. The diversity and potency of snake venoms in the region present a major public health challenge, with traditional methods of antivenom production often falling short due to the unique and complex nature of these venoms. This is where [tandem mass spectrometry](https://en.wikipedia.org/wiki/Tandem_mass_spectrometry) combined with [_de novo_ peptide sequencing](https://en.wikipedia.org/wiki/De_novo_peptide_sequencing) could potentially play a role.\n",
    "\n",
    "_De novo_ peptide sequencing involves determining the amino acid sequence of peptides from a mass spectrum without prior knowledge of the protein sequence, potentially making it a tool in the fight against snake bites. Unlike traditional database search methods, which rely on existing sequence databases and often fail when encountering novel or highly variable venom components, _de novo_ sequencing provides an unbiased and comprehensive analysis of venom peptides. This approach could potentially allow for the identification of new and unique venom peptides, which is crucial for the development of effective and specific antivenoms.\n",
    "\n",
    "By leveraging mass spectrometry with _de novo_ peptide sequencing, researchers could potentially create tailored antivenoms that are more effective against the diverse snake venom profiles found in Senegal. If successful, This may have the potential not only to improve the chances of survival for snakebite victims but also to enhance the overall public health response to snakebite emergencies. We believe that the ability to rapidly and accurately sequence venom peptides could represent a significant advancement in our efforts to combat the dangers posed by snakes in Senegal and beyond.\n",
    "\n",
    "## The Task: recalibrating model predictions\n",
    "\n",
    "How can we help? In this hackathon we will be improving existing _de novo_ peptide sequencing models. Specifically, we will be looking into recalibration and filtering! Rather than training a large _de novo_ sequencing model from scratch, we will focus on using various techniques to improve the area under the curve (AUC) for the precision-recall graph. Due to high noise, our models are often not super well calibrated.\n",
    "\n",
    "InstaDeep has developed a transformer-based _de novo_ peptide sequencing model **InstaNovo** [[preprint](https://www.biorxiv.org/content/10.1101/2023.08.30.555055v3)][[code](https://github.com/instadeepai/InstaNovo)]. \n",
    "We will provide you with the inputs AND outputs of InstaNovo along with some additional metadata (eg. retention time). The InstaNovo outputs includes the top 5 beam predictions along with their model confidences.\n",
    "Your task is to use these inputs and metadata to re-calibrate the confidence measurements and filter out any false positives in order to maximise the AUC!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Introduction to Mass Spectrometry for _De Novo_ Peptide Sequencing\n",
    "Mass spectrometry (MS) is an analytical technique used to measure the mass-to-charge ratio (m/z) of ions. It is widely used in proteomics, especially for _de novo_ sequencing, where the goal is to determine the amino acid sequence of a peptide directly from the mass spectrometric data without prior knowledge of the sequence.\n",
    "\n",
    "## Process Overview:\n",
    "- **Ionization:** The peptide sample is ionized, usually by electrospray ionization (ESI) or matrix-assisted laser desorption/ionization (MALDI), generating charged peptide ions.\n",
    "\n",
    "- **Mass Analysis (MS1):** The ionized peptides are first separated based on their m/z ratios. The resulting spectrum (MS1) shows the m/z values of the precursor ions (the intact peptides).\n",
    "\n",
    "- **Fragmentation:** Selected precursor ions are further fragmented into smaller ions. This fragmentation process is critical for _de novo_ sequencing as it generates the ion fragments needed to determine the peptide sequence.\n",
    "\n",
    "- **Mass Analysis (MS2):** The fragments are analyzed to produce an MS2 spectrum, where the mz_array represents the m/z values of the fragment ions and the intensity_array reflects their abundance.\n",
    "\n",
    "- **_De Novo_ Sequencing:** The MS2 data (mz_array and intensity_array) are used to infer the peptide sequence. By analyzing the differences between the m/z values, the sequence of the peptide can be reconstructed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "\n",
    "<figure>\n",
    "<img src='https://raw.githubusercontent.com/BioGeek/hackathon_indaba_senegal_2024/main/imgs/de_novo.png'/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "<font color='grey'>Image sources: [Vanquishâ„¢ Neo UHPLC](https://www.thermofisher.com/order/catalog/product/VN-S10-A-01) and [Orbitrap Exploris](https://www.thermofisher.com/order/catalog/product/BRE725539)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: koinapy in ./.venv/lib/python3.10/site-packages (0.0.8)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.23.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from koinapy) (4.65.0)\n",
      "Requirement already satisfied: tritonclient!=2.41 in ./.venv/lib/python3.10/site-packages (from tritonclient[grpc]!=2.41; python_version >= \"3.8\" and python_full_version <= \"3.11.0\"->koinapy) (2.41.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in ./.venv/lib/python3.10/site-packages (from tritonclient!=2.41->tritonclient[grpc]!=2.41; python_version >= \"3.8\" and python_full_version <= \"3.11.0\"->koinapy) (1.20)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in ./.venv/lib/python3.10/site-packages (from tritonclient[grpc]!=2.41; python_version >= \"3.8\" and python_full_version <= \"3.11.0\"->koinapy) (1.66.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from tritonclient[grpc]!=2.41; python_version >= \"3.8\" and python_full_version <= \"3.11.0\"->koinapy) (3.19.6)\n"
     ]
    }
   ],
   "source": [
    "# Install koinapy for Prosit API\n",
    "!pip install koinapy matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import re\n",
    "import os\n",
    "\n",
    "import koinapy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61356994",
   "metadata": {},
   "source": [
    "Download the `Train.csv` and `Test.csv` from [Zindi](https://zindi.africa/competitions/snakes-and-sequences-senegalese-serpent-venom-sequencing-hackathon/data) and put them in the `data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1879eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/Train.csv\", na_filter=\"\")\n",
    "test_df = pd.read_csv(\"data/Test.csv\", na_filter=\"\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Exploring mass-spectrometry data\n",
    "\n",
    "**To perform _de novo_ sequencing, we require both MS1 and MS2 information:**\n",
    "- From MS1:\n",
    "  - `precursor_mass` - The mass of the full peptide\n",
    "  - `precursor_mz` - The mass-to-charge of the full peptide\n",
    "  - `precursor_charge` - The charge of the peptide\n",
    "- From MS2:\n",
    "  - `mz_array` - The mass-to-charge value of each peak (x-axis)\n",
    "  - `intensity_array` - The abundance of each peak (y-axis)\n",
    "\n",
    "**Additional information:**\n",
    "- `retention_time` - The time (in minutes) it took for the peptide to elute from the HPLC\n",
    "- `exp_id` - The ID of the experiment, may be used to normalise retention time across experiments\n",
    "\n",
    "**Model outputs:**\n",
    "- `preds_beam_0` - The most confident predicted peptide\n",
    "- `log_probs_beam_0` - The log-probability under the model for the predicted peptide\n",
    "- `preds_beam_1` to `preds_beam_4` - The other beam outputs in decreasing order of confidence\n",
    "- `log_probs_beam_1` to `log_probs_beam_4` - The log-probability of the beam outputs in decreasing order of confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Quick data cleaning\n",
    "\n",
    "This code is used to convert the String format of the mz and intensity arrays into a list of floats\n",
    "\n",
    "_This is caused by saving lists of floats in csv files_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"mz_array\"] = train_df[\"mz_array\"].map(\n",
    "    lambda x: list(map(float, re.findall(r\"\\d+\\.\\d*\", x))) if isinstance(x, str) else x\n",
    ")\n",
    "train_df[\"intensity_array\"] = train_df[\"intensity_array\"].map(\n",
    "    lambda x: list(map(float, re.findall(r\"\\d+\\.\\d*\", x))) if isinstance(x, str) else x\n",
    ")\n",
    "test_df[\"mz_array\"] = train_df[\"mz_array\"].map(\n",
    "    lambda x: list(map(float, re.findall(r\"\\d+\\.\\d+\", x))) if isinstance(x, str) else x\n",
    ")\n",
    "test_df[\"intensity_array\"] = train_df[\"intensity_array\"].map(\n",
    "    lambda x: list(map(float, re.findall(r\"\\d+\\.\\d*\", x))) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Plotting a MS2 spectrum\n",
    "\n",
    "We can plot the MS2 spectrum as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df.iloc[0]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.stem(\n",
    "    row[\"mz_array\"],\n",
    "    row[\"intensity_array\"] / np.max(row[\"intensity_array\"]),\n",
    "    markerfmt=\"\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.xlabel(\"m/z\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "plt.title(f'Experimental MS2 Spectrum of {row[\"target\"]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The large peak in the middle is actually the precursor peak and not super relevant to MS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Removing precursor peak\n",
    "\n",
    "We can write some code to remove the precursor peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_precursor(mz_array, intensity_array, precursor_mz, tol=2.0):\n",
    "    # Calculate the absolute difference between mz_array and precursor_mz\n",
    "    mz_array = np.array(mz_array)\n",
    "    intensity_array = np.array(intensity_array)\n",
    "\n",
    "    diff = np.abs(mz_array - precursor_mz)\n",
    "\n",
    "    # Identify indices where the difference is within the tolerance\n",
    "    indices_to_zero = diff <= tol\n",
    "\n",
    "    # Zero out the intensity values at these indices\n",
    "    intensity_array[indices_to_zero] = 0\n",
    "\n",
    "    # Normalise here as well\n",
    "    return intensity_array / intensity_array.max()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.stem(\n",
    "    row[\"mz_array\"],\n",
    "    remove_precursor(row[\"mz_array\"], row[\"intensity_array\"], row[\"precursor_mz\"]),\n",
    "    markerfmt=\"\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.xlabel(\"m/z\")\n",
    "plt.ylabel(\"Intensity\")\n",
    "plt.title(f'Experimental MS2 Spectrum of {row[\"target\"]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "That looks much better!\n",
    "\n",
    "Let's create a filtered column for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"intensity_array_normalised\"] = train_df.apply(\n",
    "    lambda x: remove_precursor(x[\"mz_array\"], x[\"intensity_array\"], x[\"precursor_mz\"]),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Comparison to a theoretical spectrum\n",
    "\n",
    "All amino acids have a fixed mass. We can use this to calculate the theoretical spectrum of a given peptide! Let's do this for the predicted peptide.\n",
    "\n",
    "First, we will define some helper functions to calculate the mass of a sequence.\n",
    "\n",
    "After protein synthesis, some amino acids can undergo chemical alterations called [post-translational modification](https://en.wikipedia.org/wiki/Post-translational_modification) which change their masses, so we have to account for those. Also take note that the masses. Also note that the masses of the amino acids [Isoleucine](https://en.wikipedia.org/wiki/Isoleucine) and [Leucine](https://en.wikipedia.org/wiki/Leucine) are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amino acid masses\n",
    "residue_masses = {\n",
    "    \"G\": 57.021464,\n",
    "    \"A\": 71.037114,\n",
    "    \"S\": 87.032028,\n",
    "    \"P\": 97.052764,\n",
    "    \"V\": 99.068414,\n",
    "    \"T\": 101.047670,\n",
    "    \"C\": 103.009185,\n",
    "    \"L\": 113.084064,  # Beware!\n",
    "    \"I\": 113.084064,  # Mass of Isoleucine and Leucine are the same!\n",
    "    \"N\": 114.042927,\n",
    "    \"D\": 115.026943,\n",
    "    \"Q\": 128.058578,\n",
    "    \"K\": 128.094963,\n",
    "    \"E\": 129.042593,\n",
    "    \"M\": 131.040485,\n",
    "    \"H\": 137.058912,\n",
    "    \"F\": 147.068414,\n",
    "    \"R\": 156.101111,\n",
    "    \"Y\": 163.063329,\n",
    "    \"W\": 186.079313,\n",
    "    # Post-translational modifications\n",
    "    \"M(+15.99)\": 147.035400,  # Oxidation\n",
    "    \"C(+57.02)\": 160.030649,  # Cysteine alkylation\n",
    "    \"N(+.98)\": 115.026943,  # Deamidation\n",
    "    \"Q(+.98)\": 129.042594,  # Deamidation\n",
    "    \"S(+79.97)\": 166.998028,  # Phosphorylation\n",
    "    \"T(+79.97)\": 181.01367,  # Phosphorylation\n",
    "    \"Y(+79.97)\": 243.029329,  # Phosphorylation\n",
    "}\n",
    "\n",
    "tokenizer_regex = r\"(\\([^)]+\\))|([A-Z](?:\\([^)]+\\))?)\"\n",
    "\n",
    "PROTON_MASS_AMU = 1.007276\n",
    "H2O_MASS = 18.0106\n",
    "\n",
    "\n",
    "def tokenize(sequence: str) -> list[str]:\n",
    "    \"\"\"Split a peptide represented as a string into a list of residues.\n",
    "\n",
    "    Args:\n",
    "        sequence (str): The peptide to be split.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: The sequence of residues forming the peptide.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        item\n",
    "        for sublist in re.findall(tokenizer_regex, sequence)\n",
    "        for item in sublist\n",
    "        if item\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_sequence_mass(sequence: list[str], charge: int | None) -> float:\n",
    "    \"\"\"Get the mass of a sequence.\n",
    "\n",
    "    Args:\n",
    "        sequence (list[str]):\n",
    "            The residue sequence whose mass to calculate.\n",
    "            All residues must be in residue_masses or\n",
    "            this will raise a `KeyError`.\n",
    "        charge (int | None, optional):\n",
    "            Charge of the sequence to calculate the mass.\n",
    "\n",
    "    Returns:\n",
    "        float: The mass of the sequence in Daltons.\n",
    "    \"\"\"\n",
    "    mass = sum([residue_masses[residue] for residue in sequence]) + H2O_MASS\n",
    "    if charge:\n",
    "        mass = (mass / charge) + PROTON_MASS_AMU\n",
    "    return float(mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "During mass spectrometry, peptides undergo collision induced dissociation (CID) within the mass spectormeter to break bonds typically along the peptide backbone. N-terminal fragments ions are classed b-ions; C-terminal fragment ions as y-ions. \n",
    "\n",
    "<figure>\n",
    "<img src='https://www.ionsource.com/tutorial/DeNovo/art/aby_anno_frag.gif'/>\n",
    "</figure>\n",
    "\n",
    "<font color='grey'>Image source: [De Novo Peptide Sequencing Tutorial](https://www.ionsource.com/tutorial/DeNovo/nomenclature.htm)</font>\n",
    "\n",
    "\n",
    "To find the theoretical spectra, we need to compute the masses of all combinations of the peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df.iloc[0]\n",
    "\n",
    "sequence = row[\"preds_beam_0\"]\n",
    "print(f\"          Sequence: {sequence}\")\n",
    "substrings = [sequence[: i + 1] for i in range(len(sequence))][:-1]\n",
    "reverse_substrings = [sequence[i:] for i in range(len(sequence))][1:]\n",
    "print(\"        Substrings: \" + \", \".join(substrings))\n",
    "print(\"Reverse substrings: \" + \", \".join(reverse_substrings[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ions = [get_sequence_mass(x, charge=1) for x in substrings]\n",
    "y_ions = [get_sequence_mass(x, charge=1) for x in reverse_substrings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.stem(\n",
    "    row[\"mz_array\"],\n",
    "    row[\"intensity_array_normalised\"],\n",
    "    markerfmt=\"\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.stem(\n",
    "    np.array(y_ions),\n",
    "    -np.ones(len(y_ions)),\n",
    "    markerfmt=\"\",\n",
    "    linefmt=\"tab:green\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.stem(\n",
    "    np.array(b_ions) - H2O_MASS,\n",
    "    -np.ones(len(b_ions)),\n",
    "    markerfmt=\"\",\n",
    "    linefmt=\"tab:red\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.legend([\"Experimental MS2\", \"Theoretical y-ions\", \"Theoretical b-ions\"])\n",
    "plt.title(f\"Experimental MS2 of '{row['target']}'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "As you can see, the peaks actually line up quite well with the theoretical spectra! The large experimental peak in the middle that doesn't have a corresponding theoretical peak is caused by the MS1 precursor and is generally removed before running InstaNovo.\n",
    "\n",
    "**Hint: If we are able to compare the theoretical spectra to our experimental spectra, perhaps we could use this for filtering? If we predict the wrong peptide, it probably won't look similar to the experimental spectra! Could we do the same for Retention Time?**\n",
    "\n",
    "Functions that might help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theoretical_spectrum(sequence):\n",
    "    \"\"\"Calculate theoretical y- and b- ions of a peptide.\"\"\"\n",
    "    if isinstance(sequence, str):\n",
    "        sequence = tokenize(sequence)\n",
    "    substrings = [sequence[: i + 1] for i in range(len(sequence))][:-1]\n",
    "    reverse_substrings = [sequence[i:] for i in range(len(sequence))][1:]\n",
    "    b_ions = [get_sequence_mass(x, charge=1) for x in substrings]\n",
    "    y_ions = [get_sequence_mass(x, charge=1) for x in reverse_substrings]\n",
    "    return np.concatenate([np.array(b_ions) - H2O_MASS, np.array(y_ions)])\n",
    "\n",
    "\n",
    "def get_num_match(sequence, mz_array, tolerance=0.4):\n",
    "    \"\"\"Calculate the number of matching peaks.\"\"\"\n",
    "    experimental_spectrum = np.array(mz_array)\n",
    "    theoretical_spectrum = np.array(get_theoretical_spectrum(sequence))\n",
    "    differences = np.abs(experimental_spectrum[:, None] - theoretical_spectrum)\n",
    "\n",
    "    # Count the number of experimental peaks that have at least one matching theoretical peak\n",
    "    num_match = np.sum(np.any(differences < tolerance, axis=1))\n",
    "\n",
    "    return num_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Improved theoretical spectrum with Prosit\n",
    "\n",
    "We can improve our predicted spectrum with a tool like [Prosit](https://www.nature.com/articles/s41592-019-0426-7).\n",
    "\n",
    "Prosit is a model trained to predict MS2 spectra given a peptide. We can call this model through [koinapy](https://pypi.org/project/koinapy/0.0.8/). See the example below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_modification(peptide):\n",
    "    mapping = {\n",
    "        # Prosit uses a different notation for these modifications\n",
    "        \"M(+15.99)\": \"M[UNIMOD:35]\",\n",
    "        \"C(+57.02)\": \"C[UNIMOD:4]\",\n",
    "        # Deamidation not supported by Prosit\n",
    "        \"N(+.98)\": \"N\",\n",
    "        \"Q(+.98)\": \"Q\",\n",
    "        # Phosphorylation not supported by Prosit\n",
    "        \"S(+79.97)\": \"S\",\n",
    "        \"T(+79.97)\": \"T\",\n",
    "        \"Y(+79.97)\": \"Y\",\n",
    "    }\n",
    "    return [mapping[residue] if residue in mapping else residue for residue in peptide]\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = koinapy.Koina(\"Prosit_2020_intensity_HCD\", \"koina.wilhelmlab.org:443\")\n",
    "\n",
    "\n",
    "def compute_ion_identifications(\n",
    "    dataset: pd.DataFrame, source_column: str, mz_tolerance: float\n",
    "):\n",
    "    matches = [\n",
    "        find_matching_ions(\n",
    "            source_mz=row[source_column],\n",
    "            target_mz=row[\"mz_array\"],\n",
    "            target_intensities=row[\"intensity_array\"],\n",
    "            mz_tolerance=mz_tolerance,\n",
    "        )\n",
    "        for _, row in dataset.iterrows()\n",
    "    ]\n",
    "    return zip(*matches)\n",
    "\n",
    "\n",
    "def find_matching_ions(\n",
    "    source_mz: list[float],\n",
    "    target_mz: list[float],\n",
    "    target_intensities: list[float],\n",
    "    mz_tolerance: float,\n",
    ") -> tuple[list[float], list[float]]:\n",
    "    try:\n",
    "        num_matches, match_intensity = 0, 0.0\n",
    "        for ion_mz in source_mz:\n",
    "            nearest = bisect.bisect_left(target_mz, ion_mz)\n",
    "            if nearest < len(target_mz):\n",
    "                if target_mz[nearest] - ion_mz < mz_tolerance:\n",
    "                    num_matches += 1\n",
    "                    match_intensity += target_intensities[nearest]\n",
    "                    continue\n",
    "            if nearest > 0:\n",
    "                if ion_mz - target_mz[nearest - 1] < mz_tolerance:\n",
    "                    num_matches += 1\n",
    "                    match_intensity += target_intensities[nearest - 1]\n",
    "        return num_matches / len(source_mz), match_intensity / sum(target_intensities)\n",
    "    except TypeError:\n",
    "        print(source_mz)\n",
    "\n",
    "\n",
    "def compute_prosit_features(mz_tolerance: float, dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    inputs = pd.DataFrame()\n",
    "    inputs[\"peptide_sequences\"] = np.array(\n",
    "        [\"\".join(peptide) for peptide in dataset[\"prediction\"].apply(map_modification)]\n",
    "    )\n",
    "    inputs[\"precursor_charges\"] = np.array(dataset[\"precursor_charge\"])\n",
    "    inputs[\"collision_energies\"] = np.array(len(dataset) * [25])\n",
    "\n",
    "    predictions: pd.DataFrame = model.predict(inputs, debug=True)\n",
    "    predictions[\"Index\"] = predictions.index\n",
    "\n",
    "    grouped_predictions = predictions.groupby(by=\"Index\").agg(\n",
    "        {\n",
    "            \"peptide_sequences\": \"first\",\n",
    "            \"precursor_charges\": \"first\",\n",
    "            \"collision_energies\": \"first\",\n",
    "            \"intensities\": list,\n",
    "            \"mz\": list,\n",
    "            \"annotation\": list,\n",
    "        }\n",
    "    )\n",
    "    grouped_predictions[\"intensities\"] = grouped_predictions.apply(\n",
    "        lambda row: np.array(row[\"intensities\"])[np.argsort(row[\"mz\"])].tolist(), axis=1\n",
    "    )\n",
    "    grouped_predictions[\"annotation\"] = grouped_predictions.apply(\n",
    "        lambda row: np.array(row[\"annotation\"])[np.argsort(row[\"mz\"])].tolist(), axis=1\n",
    "    )\n",
    "    grouped_predictions[\"mz\"] = grouped_predictions[\"mz\"].apply(np.sort)\n",
    "    dataset[\"prosit_mz\"] = grouped_predictions[\"mz\"]\n",
    "    dataset[\"prosit_intensity\"] = grouped_predictions[\"intensities\"]\n",
    "\n",
    "    ion_matches, match_intensity = compute_ion_identifications(\n",
    "        dataset=dataset, source_column=\"prosit_mz\", mz_tolerance=mz_tolerance\n",
    "    )\n",
    "    dataset[\"ion_matches\"] = ion_matches\n",
    "    dataset[\"ion_match_intensity\"] = match_intensity\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_df[\"preds_beam_0\"].map(lambda x: len(x) > 0)\n",
    "\n",
    "subset_df = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": train_df.loc[idx, \"ID\"],\n",
    "        \"prediction\": train_df.loc[idx, \"preds_beam_0\"].map(lambda x: tokenize(x)),\n",
    "        \"precursor_charge\": train_df.loc[idx, \"precursor_charge\"],\n",
    "        \"mz_array\": train_df.loc[idx, \"mz_array\"],\n",
    "        \"intensity_array\": train_df.loc[idx, \"intensity_array_normalised\"],\n",
    "    }\n",
    ").reset_index(drop=True)\n",
    "\n",
    "subset_df = compute_prosit_features(0.02, subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "The function above has added a few new columns to our `subset_df`:\n",
    "- `prosit_mz` - predicted mz of prosit\n",
    "- `prosit_intensity` - predicted intensity of prosit\n",
    "- `ion_matches` - a score of ion matches\n",
    "- `ion_match_intensity` - a score of how well the intensities match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "prosit_row = subset_df.iloc[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.stem(\n",
    "    prosit_row[\"mz_array\"],\n",
    "    prosit_row[\"intensity_array\"] / np.max(prosit_row[\"intensity_array\"]),\n",
    "    markerfmt=\"\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.stem(\n",
    "    prosit_row[\"prosit_mz\"],\n",
    "    -np.array(prosit_row[\"prosit_intensity\"]),\n",
    "    linefmt=\"tab:red\",\n",
    "    markerfmt=\"\",\n",
    "    basefmt=\"black\",\n",
    ")\n",
    "plt.legend([\"Experimental MS2\", \"Prosit MS2\"])\n",
    "plt.title(f\"Experimental MS2 of '{''.join(prosit_row['prediction'])}'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "This looks much better than our simple approach from before! We still don't catch all the peaks, but some of these may also be noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Calculating AUC and improving the curve\n",
    "\n",
    "Below we have included some code to help calculate AUC and plot the precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc(targets, preds, log_probs, label=None, plot=True, xlim=0.7):\n",
    "    conf = np.exp(log_probs)\n",
    "    order = conf.argsort()[::-1]\n",
    "    matches = np.array(targets == preds)\n",
    "    matches = matches[order]\n",
    "    conf = conf[order]\n",
    "\n",
    "    csum = np.cumsum(matches)\n",
    "    precision = csum / (np.arange(len(matches)) + 1)\n",
    "    recall = csum / len(matches)\n",
    "\n",
    "    # Calculate AUC\n",
    "    width = recall[1:] - recall[:-1]\n",
    "    height = np.minimum(precision[1:], precision[:-1])\n",
    "    top = np.maximum(precision[1:], precision[:-1])\n",
    "    side = top - height\n",
    "    auc = (width * height).sum() + 0.5 * (side * width).sum()\n",
    "\n",
    "    # Plot\n",
    "    if plot:\n",
    "        if label:\n",
    "            plt.plot(recall, precision, label=f\"{label} (AUC = {auc:.3f})\")\n",
    "        else:\n",
    "            plt.plot(recall, precision, label=f\"AUC = {auc:.3f}\")\n",
    "        plt.xlim(0, xlim)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel(\"Recall\")\n",
    "        plt.ylabel(\"Precision\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = calculate_auc(\n",
    "    train_df[\"target\"], train_df[\"preds_beam_0\"], train_df[\"log_probs_beam_0\"]\n",
    ")\n",
    "print(f\"AUC: {auc:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "The precision-recall curve looks pretty good for `train_df`!\n",
    "\n",
    "_Note: `train_df` is actually a calibration set and our model has never seen these peptides!_\n",
    "\n",
    "We can calculate the AUC plot the precision-recall curve for all five beams. As one might expect, the one with the highest log-probabilities (beam 0) does the best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beam in range(5):\n",
    "    auc = calculate_auc(\n",
    "        train_df[\"target\"],\n",
    "        train_df[f\"preds_beam_{beam}\"],\n",
    "        train_df[f\"log_probs_beam_{beam}\"],\n",
    "        label=f\"Beam {beam}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "As one might expect, the performance gets significantly worse as we try the other beams but there may still be some useful information in them, especially the rank 2 beams (`beam_preds_1`). Perhaps there is some way to select the rank 2 beam if we know the rank 1 beam is incorrect?\n",
    "\n",
    "**Hint: try comparing the theoretical mass of the predicted sequence to the precursor mass!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## Filtering on precursor mass\n",
    "\n",
    "Here is a function that can be used to check whether a sequence matches the precursor to some PPM tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to consider isotopes! We will consider 0 to 1, but try using more!\n",
    "max_isotope_error = 1\n",
    "CARBON_MASS_DELTA = 1.00335\n",
    "\n",
    "\n",
    "def _calc_mass_error(\n",
    "    mz_theoretical: float, mz_measured: float, charge: int, isotope: int = 0\n",
    ") -> float:\n",
    "    \"\"\"Calculate the mass error between theoretical and actual mz in ppm.\"\"\"\n",
    "    return float(\n",
    "        (mz_theoretical - (mz_measured - isotope * CARBON_MASS_DELTA / charge))\n",
    "        / mz_measured\n",
    "        * 10**6\n",
    "    )\n",
    "\n",
    "\n",
    "def _mass(seq: str | list[str], charge: int | None = None) -> float:\n",
    "    \"\"\"Calculate a peptide's mass or m/z.\"\"\"\n",
    "    if isinstance(seq, str):\n",
    "        seq = tokenize(seq)\n",
    "    return get_sequence_mass(seq, charge)\n",
    "\n",
    "\n",
    "def matches_precursor(\n",
    "    seq: str | list[str],\n",
    "    prec_mass: float,\n",
    "    prec_charge: int,\n",
    "    prec_tol: int = 50,\n",
    ") -> tuple[bool, list[float]]:\n",
    "    \"\"\"Check if a sequence matches the precursor mass within some tolerance.\"\"\"\n",
    "    seq_mass = _mass(seq, charge=prec_charge)\n",
    "    delta_mass_ppm = [\n",
    "        _calc_mass_error(seq_mass, prec_mass, prec_charge, isotope)\n",
    "        for isotope in range(0, max_isotope_error + 1)\n",
    "    ]\n",
    "    return any(abs(d) < prec_tol for d in delta_mass_ppm), delta_mass_ppm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "We can use this to try and filter our predictions to a tighter tolerance of 20ppm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate whether it matches precursor for all beams\n",
    "for i in range(5):\n",
    "    train_df[f\"delta_ppm_{i}\"] = np.array(\n",
    "        [\n",
    "            # Find lowest ppm for all isotopes\n",
    "            np.min(\n",
    "                np.abs(\n",
    "                    matches_precursor(\n",
    "                        row[f\"preds_beam_{i}\"],\n",
    "                        row[\"precursor_mz\"],\n",
    "                        row[\"precursor_charge\"],\n",
    "                        prec_tol=20,\n",
    "                    )[1]\n",
    "                )\n",
    "            )\n",
    "            if len(row[f\"preds_beam_{i}\"]) > 0\n",
    "            else np.inf\n",
    "            for _, row in train_df.iterrows()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppm_tol = 20\n",
    "\n",
    "preds = []\n",
    "probs = []\n",
    "for _, row in train_df.iterrows():\n",
    "    pred = \"\"\n",
    "    prob = -np.inf\n",
    "    for i in range(5):\n",
    "        if row[f\"delta_ppm_{i}\"] < ppm_tol:\n",
    "            pred = row[f\"preds_beam_{i}\"]\n",
    "            prob = row[f\"log_probs_beam_{i}\"]\n",
    "            break\n",
    "    preds.append(pred)\n",
    "    probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"preds_filtered\"] = preds\n",
    "train_df[\"probs_filtered\"] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = calculate_auc(\n",
    "    train_df[\"target\"],\n",
    "    train_df[\"preds_beam_0\"],\n",
    "    train_df[\"log_probs_beam_0\"],\n",
    "    label=\"Original\",\n",
    ")\n",
    "print(f\"Original AUC: {auc:.6f}\\n\")\n",
    "filtered_auc = calculate_auc(\n",
    "    train_df[\"target\"],\n",
    "    train_df[\"preds_filtered\"],\n",
    "    train_df[\"probs_filtered\"],\n",
    "    label=\"Filtered\",\n",
    ")\n",
    "print(f\"Filtered AUC: {filtered_auc:.6f}\\n\")\n",
    "plt.ylim([0.6, 1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Very small improvement but it works. This is just a proof-of-concept, you should try some other techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Using logistic regression\n",
    "\n",
    "We will now do a simple logistic regression example to try and predict whether a sample is a false positive or not. \n",
    "\n",
    "First we will create a train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prosit features to training set\n",
    "data_df = train_df.merge(\n",
    "    subset_df[[\"ID\", \"ion_matches\", \"ion_match_intensity\"]], on=\"ID\", how=\"left\"\n",
    ").copy()\n",
    "data_df[\"ion_matches\"] = data_df[\"ion_matches\"].fillna(0.0)\n",
    "data_df[\"ion_match_intensity\"] = data_df[\"ion_match_intensity\"].fillna(0.0)\n",
    "data_df[\"delta_ppm_0\"] = data_df[\"delta_ppm_0\"].replace(np.inf, 1000)\n",
    "data_df[\"log_probs_beam_0\"] = data_df[\"log_probs_beam_0\"].replace(-np.inf, -100)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data_df, random_state=42, test_size=0.1)\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train[\"target\"] == train[\"preds_beam_0\"]\n",
    "valid_labels = valid[\"target\"] == valid[\"preds_beam_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"precursor_mz\",\n",
    "    \"precursor_charge\",\n",
    "    \"delta_ppm_0\",\n",
    "    \"ion_matches\",\n",
    "    \"ion_match_intensity\",\n",
    "]\n",
    "\n",
    "X_train = train[features]\n",
    "X_valid = valid[features]\n",
    "\n",
    "# Change the C\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_valid)\n",
    "probs = clf.predict_proba(X_valid)\n",
    "\n",
    "accuracy_score(valid_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Plot the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(valid_labels, preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = range(len(set(valid_labels)))\n",
    "plt.xticks(tick_marks, tick_marks)\n",
    "plt.yticks(tick_marks, tick_marks)\n",
    "\n",
    "# Labeling the axes\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "\n",
    "# Adding the numbers in the cells\n",
    "thresh = conf_matrix.max() / 2.0\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(conf_matrix[i, j], \"d\"),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if conf_matrix[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(valid_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "So we can predict with reasonable accuracy when prediction is incorrect, how does these affect AUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds = valid[\"preds_filtered\"].copy()\n",
    "filtered_probs = valid[\"probs_filtered\"].copy()\n",
    "\n",
    "idx = (preds == 0) & (probs[:, 0] > 0.85)\n",
    "filtered_preds.loc[idx] = \"\"\n",
    "filtered_probs.loc[idx] = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = calculate_auc(\n",
    "    valid[\"target\"], valid[\"preds_beam_0\"], valid[\"log_probs_beam_0\"], label=\"Original\"\n",
    ")\n",
    "print(f\"Original AUC: {auc:.6f}\\n\")\n",
    "filtered_auc = calculate_auc(\n",
    "    valid[\"target\"], filtered_preds, filtered_probs, label=\"Filtered\"\n",
    ")\n",
    "print(f\"Filtered AUC: {filtered_auc:.6f}\\n\")\n",
    "plt.ylim([0.6, 1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "It works, but can definitely be improved!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## Creating a submission file\n",
    "\n",
    "Since we now know beam 0 is the best, let's try create a submission file to get a baseline AUC score on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "In our submission file, we expect you to submit the predicted peptide along with the model confidence.\n",
    "\n",
    "_NOTE: Model confidence is not log probabilities! Use `np.exp()`!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_df[[\"ID\"]].copy()\n",
    "sub_df[\"target\"] = test_df[\"preds_beam_0\"]\n",
    "sub_df[\"confidence\"] = np.exp(test_df[\"log_probs_beam_0\"])\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Save to a csv file for uploading to Zindi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"SampleSumbission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
